{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, cv2, math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_face_part_detect(img_vec):\n",
    "    gray = np.array(img_vec, dtype='uint8')\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 7)\n",
    "    if len(faces)>0:\n",
    "        for (x,y,w,h) in faces:\n",
    "            return img_vec[x:x+w,y:y+h]\n",
    "    return img_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the pre-processing:\n",
    "# train, test are arrays containg tupule (i,j) where i is the label of image, eg. Subject01. \n",
    "# j in the tupule is flattened image matrix.\n",
    "# A matrix contains images as rows (M, N**2) dimension. M: number of images N**2: number of pixels\n",
    "TRAINING_IMAGES_OUT_OF_ELEVEN = 7\n",
    "LENGTH = 243\n",
    "WIDTH = 320\n",
    "PROD = LENGTH*WIDTH\n",
    "BASE_FOLDER = \"data/\"\n",
    "ls = os.listdir(BASE_FOLDER)\n",
    "d = dict()\n",
    "#Creating label for each image.\n",
    "for i in range(1,10):\n",
    "    d[\"subject0\"+str(i)] = []\n",
    "for i in range(10, 16):\n",
    "    d[\"subject\"+str(i)] = []\n",
    "for i in ls:\n",
    "    img = Image.open(BASE_FOLDER+i)\n",
    "    img = np.array(img, dtype = np.uint8)\n",
    "#     img = cv2.resize(img,(LENGTH, WIDTH))\n",
    "#     img = only_face_part_detect(img)\n",
    "#     img = cv2.resize(img,(LENGTH, WIDTH))\n",
    "    img = img.flatten()\n",
    "    d[i[:9]].append(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2) (105, 2)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "for i in d:\n",
    "    for j in d[i][:TRAINING_IMAGES_OUT_OF_ELEVEN]:\n",
    "        train.append((i,j))\n",
    "    for j in d[i][TRAINING_IMAGES_OUT_OF_ELEVEN:]:\n",
    "        test.append((i,j))\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "print(test.shape, train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ndarray((len(train), PROD))\n",
    "for i in range(len(train)):\n",
    "    A[i] = train[i][1]\n",
    "# Summarizing the pre-processing:\n",
    "# train, test are arrays containg tupule (i,j) where i is the label of image, eg. Subject01. \n",
    "# j in the tupule is flattened image matrix.\n",
    "# A matrix contains images as rows (M, N**2) dimension. M: number of images N**2: number of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123.45714286 123.53333333 123.74285714 ...  68.          68.\n",
      "  68.        ]\n",
      "(77760, 105)\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(A, axis=0)\n",
    "print(mean)\n",
    "A = A - mean\n",
    "# A according to the paper consists of coloumns representing images (N**2, M) dimensions\n",
    "A = np.transpose(A)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SEE MEAN IMAGE uncomment this portion.\n",
    "mean_arr  = np.resize(mean, (LENGTH, WIDTH))\n",
    "cv2.imshow(\"original\", np.array(mean_arr, dtype = np.uint8))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.imwrite(\"mean.jpg\", mean_arr)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Algorithm implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77760, 105)\n",
      "(105, 105)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "L = np.dot(np.transpose(A), A)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:)\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "eigenval, eigenvec = LA.eigh(L)\n",
    "# eigenvec = eigenvec.tolist()\n",
    "print(\"Done:)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of eigenvectors 105\n",
      "After PCA number of eigenvectors 16\n"
     ]
    }
   ],
   "source": [
    "# We take those eigenvectors corresponding to 0.85 of total energy of eigenvalues.\n",
    "w2 = eigenval\n",
    "w2 = w2/sum(w2)\n",
    "energy = 0.85\n",
    "target = []\n",
    "while(energy>0):\n",
    "    x = np.argmax(w2)\n",
    "    energy-=w2[x]\n",
    "    target.append(x)\n",
    "    w2[x] = 0\n",
    "print(\"Original number of eigenvectors\",len(eigenvec))\n",
    "eigenvec = eigenvec[:, target]\n",
    "print(\"After PCA number of eigenvectors\",eigenvec.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A*A.T eigenvectors and normalizing eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77760, 16)\n",
      "(77760, 16)\n"
     ]
    }
   ],
   "source": [
    "# A*A.T eigenvec are denoted by u \n",
    "u = np.dot(A, eigenvec)\n",
    "print(u.shape)\n",
    "norms = np.linalg.norm(u, axis = 0)\n",
    "u = u / norms\n",
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights are vector representation of each training image on the eigenface plane\n",
    "weights = np.dot(np.transpose(u), A)\n",
    "# Projection gives projection of each training image on eigenface plane\n",
    "projection = np.dot(weights.T, u.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualizing projections of 3 images uncomment and run the following code. \n",
    "# Press any key to continue on image displayed. \n",
    "# for i in [1,14,24]:\n",
    "#     mean_arr  = np.resize(A[:,i], (LENGTH, WIDTH))\n",
    "#     cv2.imshow(\"original_without_mean\"+str(i)+\".jpg\", np.array(mean_arr, dtype = np.uint8))\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(\"original_without_mean\"+str(i)+\".jpg\", np.array(mean_arr, dtype = np.uint8))\n",
    "#     mean_arr  = np.resize(A[:,i]+mean, (LENGTH, WIDTH))\n",
    "#     cv2.imshow(\"original\", np.array(mean_arr, dtype = np.uint8))\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(\"original\"+str(i)+\".jpg\", np.array(mean_arr, dtype = np.uint8))\n",
    "#     mean_arr  = np.resize(projection[i], (LENGTH, WIDTH))\n",
    "#     cv2.imshow(\"projection\", np.array(mean_arr, dtype = np.uint8))\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(\"prediction\"+str(i)+\".jpg\", np.array(mean_arr, dtype = np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_vector, weights):\n",
    "    ans_ = 10**20\n",
    "    index = -1\n",
    "    for ct,i in enumerate(np.transpose(weights)):\n",
    "        # Looping over all training images to find the closest match.\n",
    "        tans_ = np.linalg.norm(i-test_vector)\n",
    "        if tans_<ans_:\n",
    "            # If norm distance less than any previous assign index to it\n",
    "            ans_ = tans_\n",
    "            index = ct\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions:  86.67 %\n"
     ]
    }
   ],
   "source": [
    "#Finding vector representation of all input images.\n",
    "acc = 0\n",
    "for test_img in test:\n",
    "    # Loading label and flattened test image\n",
    "    label = test_img[0]\n",
    "    test_img = test_img[1]\n",
    "    #Subracting mean from test image\n",
    "    test_img = test_img - mean\n",
    "    # Finding weights of eigenface space represenatation\n",
    "    test_vector = np.dot(np.transpose(u), test_img)\n",
    "    # Calling predict unction to find closest training image to this image.\n",
    "    prediction = predict(test_vector, weights)\n",
    "    # If test_label match the predicted label increase acc.\n",
    "    if train[prediction][0] == label:\n",
    "        acc += 1\n",
    "print(\"Accuracy of predictions: \",round(acc/len(test)*100, 2), \"%\")\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
